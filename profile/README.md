# Fantasy AIGC Family

Fantasy AIGC Family is an open-source initiative exploring Human-centric AI, World Modeling, and Human-World Interaction, aiming to bridge perception, understanding, and generation in the real and digital worlds.

## ğŸ”¥ğŸ”¥ğŸ”¥ News!!
* ğŸ› **Jan 2026** â€“ [FantasyVLN](https://fantasy-amap.github.io/fantasy-vln/) is accepted by CVPR 2026.
* ğŸ› **Jan 2026** â€“ [FantasyWorld](https://fantasy-amap.github.io/fantasy-world/) is accepted by ICLR 2026.
* ğŸ“¢ **Jan 2026** â€“ We released the training and inference code and model weights of [FantasyVLN](https://fantasy-amap.github.io/fantasy-vln/).
* ğŸ† **Dec 2025** - [FantasyWorld](https://fantasy-amap.github.io/fantasy-world/) ranked **1st** on the [WorldScore](https://huggingface.co/spaces/Howieeeee/WorldScore_Leaderboard) Leaderboard (by **Stanford Prof. Fei-Fei Li's Team**), validating our approach against global state-of-the-art models.
* ğŸ› **Nov 2025** â€“ Two papers from our family, [FantasyTalking2](https://fantasy-amap.github.io/fantasy-talking2/) and [FantasyHSI](https://fantasy-amap.github.io/fantasy-hsi/), have been accepted to **AAAI 2026**.
* ğŸ› **Nov 2025** â€“ Two papers from our family, [FantasyTalking2](https://fantasy-amap.github.io/fantasy-talking2/) and [FantasyHSI](https://fantasy-amap.github.io/fantasy-hsi/), have been accepted to **AAAI 2026**.
* ğŸ› **Jul 2025** â€“ [FantasyTalking](https://fantasy-amap.github.io/fantasy-talking/) is accepted by **ACM MM 2025**.
* ğŸ“¢ **Apr 2025** â€“ We released the inference code and model weights of [FantasyTalking](https://fantasy-amap.github.io/fantasy-talking/) and [FantasyID](https://fantasy-amap.github.io/fantasy-id/).

## âœ¨âœ¨âœ¨ Members

### FantasyVLN

[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyVLN-blue.svg)](https://fantasy-amap.github.io/fantasy-vln/)
[![arXiv](https://img.shields.io/badge/Arxiv-2601.13976-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2601.13976)
[![GitHub](https://img.shields.io/badge/Code-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-vln)
![GitHub Stars](https://img.shields.io/github/stars/Fantasy-AMAP/fantasy-vln)
[![HuggingFace Model](https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E.svg)](https://huggingface.co/acvlab/FantasyVLN)
[![ModelScope](https://img.shields.io/badge/ğŸ‘¾-ModelScope-604DF4.svg)](https://modelscope.cn/models/amap_cvlab/FantasyVLN)

A unified multimodal Chain-of-Thought (CoT) reasoning framework that internalizes the inference capabilities of world models into the VLN architecture, enabling efficient and precise navigation based on natural language instructions and visual observations.
<br><br>

### FantasyWorld

[![Conference](https://img.shields.io/badge/%F0%9F%8F%9B%20%20Conference-ICLR%202026-green.svg)]()
[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyWorld-blue.svg)](https://fantasy-amap.github.io/fantasy-world/)
[![arXiv](https://img.shields.io/badge/Arxiv-2509.21657-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2509.21657)
[![GitHub](https://img.shields.io/badge/Code%20%28Comming%20Soon%29-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-world)

Corresponds to the "Worlds" dimension. A unified world model integrating video priors and geometric grounding for synthesizing explorable and geometrically consistent 3D scenes. It emphasizes spatiotemporal consistency driven by Action and serves as a verifiable structural anchor for spatial intelligence.
<br><br>

### FantasyTalking

[![Conference](https://img.shields.io/badge/%F0%9F%8F%9B%20%20Conference-ACM%20MM%202025-green.svg)](https://dl.acm.org/doi/10.1145/3746027.3755217)
[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyTalking-blue.svg)](https://fantasy-amap.github.io/fantasy-talking/)
[![arXiv](https://img.shields.io/badge/Arxiv-2504.04842-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2504.04842)
[![GitHub](https://img.shields.io/badge/Code-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-talking)
![GitHub Stars](https://img.shields.io/github/stars/Fantasy-AMAP/fantasy-talking)
[![HuggingFace Model](https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E.svg)](https://huggingface.co/acvlab/FantasyTalking)
[![HuggingFace Space](https://img.shields.io/badge/ğŸ¤—-HuggingFace%20Space-FFD21E.svg)](https://huggingface.co/spaces/acvlab/FantasyTalking)
[![ModelScope](https://img.shields.io/badge/ğŸ‘¾-ModelScope-604DF4.svg)](https://modelscope.cn/models/amap_cvlab/FantasyTalking)

The first Wan-based high-fidelity audio-driven avatar system that synchronizes facial expressions, lip motion, and body gestures in dynamic scenes through dual-stage audio-visual alignment and controllable motion modulation.
<br><br>

### FantasyTalking2

[![Conference](https://img.shields.io/badge/%F0%9F%8F%9B%20%20Conference-AAAI%202026-green.svg)](https://doi.org/10.48550/arXiv.2508.11255)
[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyTalking2-blue.svg)](https://fantasy-amap.github.io/fantasy-talking2/)
[![arXiv](https://img.shields.io/badge/Arxiv-2508.11255v1-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2508.11255v1)
[![GitHub](https://img.shields.io/badge/Code%20%28Comming%20Soon%29-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-talking2)

A novel Timestep-Layer Adaptive Multi-Expert Preference Optimization (TLPO) method enhances the quality of audio-driven avatar in three dimensions: lip-sync, motion naturalness, and visual quality.
<br><br>

### FantasyPortrait

[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyPortrait-blue.svg)](https://fantasy-amap.github.io/fantasy-portrait/)
[![arXiv](https://img.shields.io/badge/Arxiv-2507.12956-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2507.12956)
[![GitHub](https://img.shields.io/badge/Code-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-portrait)
![GitHub Stars](https://img.shields.io/github/stars/Fantasy-AMAP/fantasy-portrait)

A novel expression-driven video-generation method that pairs emotion-enhanced learning with masked cross-attention, enabling the creation of high-quality, richly expressive animations for both single and multi-portrait scenarios.
<br><br>

### FantasyHSI

[![Conference](https://img.shields.io/badge/%F0%9F%8F%9B%20%20Conference-AAAI%202026-green.svg)](https://doi.org/10.48550/arXiv.2509.01232)
[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyHSI-blue.svg)](https://fantasy-amap.github.io/fantasy-hsi/)
[![arXiv](https://img.shields.io/badge/Arxiv-2509.01232-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2509.01232)
[![GitHub](https://img.shields.io/badge/Code%20%28Comming%20Soon%29-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-hsi)

Corresponds to the "Interaction" dimension. A graph-based multi-agent framework that grounds video generation within 3D world dynamics. It unifies the action space with a broader interaction loop, transforming video generation from a content endpoint into a control channel for interactive systems.
<br><br>

### FantasyID

[![Project](https://img.shields.io/badge/ğŸŒ%20%20Project-FantasyID-blue.svg)](https://fantasy-amap.github.io/fantasy-id/)
[![arXiv](https://img.shields.io/badge/Arxiv-2502.13995-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2502.13995)
[![GitHub](https://img.shields.io/badge/Code-GitHub-181717.svg?logo=GitHub)](https://github.com/Fantasy-AMAP/fantasy-id)
![GitHub Stars](https://img.shields.io/github/stars/Fantasy-AMAP/fantasy-id)
[![HuggingFace Model](https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E.svg)](https://huggingface.co/acvlab/FantasyID)
[![ModelScope](https://img.shields.io/badge/ğŸ‘¾-ModelScope-604DF4.svg)](https://modelscope.cn/models/amap_cvlab/FantasyID)

A tuning-free text-to-video model that leverages 3D facial priors, multi-view augmentation, and layer-aware guidance injection to deliver dynamic, identity-preserving video generation.
<br><br>

## ğŸŒŸğŸŒŸğŸŒŸ Our wishes.
1. **Giving Back to the Community**: In our daily work, we benefit immensely from the resources, expertise, and support of the open source community, and we aim to give back by making our own projects open source.
2. **Attracting More Contributors**: By open sourcing our code, we invite developers worldwide to collaborateâ€”making our models smarter, our engineering more robust, and extending benefits to even more users.
3. **Building an Open Ecosystem**: We believe that open source brings together diverse expertise to create a collaborative innovation platformâ€”driving technological progress, industry growth, and broader societal impact.
